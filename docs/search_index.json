[["index.html", "ウェブ最適化ではじめる機械学習 in R 概要", " ウェブ最適化ではじめる機械学習 in R Masayuki Sakai 2023-04-11 概要 本稿は(飯塚修平 2020)の学習と実装をRで行ったものをまとめたものである． また，このbookの内容はRの実装も含めてGitHubのリポジトリで公開している． References "],["id_01-intro.html", "1 A/Bテストから始めよう：ベイズ統計による仮説検定入門", " 1 A/Bテストから始めよう：ベイズ統計による仮説検定入門 A/Bテストはシンプルで実装も簡単 ビジネスに大きな影響をもたらしうる強力な手法 正しく実行することは難しい 本章ではA/Bテストを用いて数理的に意思決定する方法を学ぶ． "],["id_01-01-situation.html", "1.1 状況設定", " 1.1 状況設定 ここでは以下のような状況を想定して議論を進める． あるECサイトがあり，企業Xが運営している． Xの従業員2人がそれぞれ異なるページの改善を目的にA/Bテストを実施，レポートを作成した． Table 1.1: AliceとBobのレポート analyst description A B Alice クリック数 2.00 4.00 Alice クリック率 0.05 0.08 Alice 表示回数 40.00 50.00 Bob クリック数 64.00 128.00 Bob クリック率 0.05 0.08 Bob 表示回数 1280.00 1600.00 どちらの結果もB案の方がクリック率の意味で良い，という内容になっている． しかし，試行回数を見ると明らかにBobの方が多く信頼できそうである． 一方，Aliceの方の結果も正しいとするならば，より少ないサンプルで答えを導き出せた という意味で優秀と考えられる． 1.1.1 データ生成のプロセス あるページについて異なるデザイン（A/B）を作成してテストした結果，クリック率が異なる． という状況から，デザインが異なれば（真の）クリック率も異なるという仮説が立てられる． ただし，この段階ではテストの結果がそのまま妥当なのかどうかは不明である．\\(\\text{ctr}_A &gt; \\text{ctr}_B\\)とか\\(\\text{ctr}_A &lt; \\text{ctr}_B\\)のような関係の正当性は主張できない． いま\\(\\theta_i = \\text{ctr}_i\\)と表しておくと，これは割合であることから \\[ \\theta_i \\in [0, 1] \\] とできる．これはあるユーザーがページ\\(i\\)を訪れたときにクリックする確率と解釈できる． また実際にクリックした場合を\\(r=1\\)，しなかった場合を\\(r=0\\)としておく． ここでは単純にクリック\\(r\\)が生起確率\\(\\theta\\)のベルヌーイ分布\\(p(r|\\theta)\\)に従うと考えていく． また，\\(\\theta\\)自体も確率変数であり\\(p(\\theta)\\)というある確率分布に従うと考える． \\(p(\\theta)\\)をどのように設定するかは分析者に委ねられる． "],["id_01-02-pdf-approximation.html", "1.2 離散化による確率密度関数の近似", " 1.2 離散化による確率密度関数の近似 以下のような関数\\(f:[-1, 1] \\rightarrow [0, 1]\\)を考えてみる． \\[ f(x) = \\begin{cases} x + 1 &amp; (-1 \\leq x \\leq 0) \\\\ -x + 1 &amp; (0 &lt; x \\leq 1) \\end{cases} \\] この時定義域\\([-1, 1]\\)を適当な数\\(n\\)で均等に分割して，その中央値をその領域の関数値とした階段関数で近似すると以下のようになる． sample_n &lt;- 1000 f &lt;- function(x) { ans &lt;- ifelse(x &lt;= 0, x+1, -x+1) return(ans) } x &lt;- seq(-1, 1, length.out=sample_n) y &lt;- f(x) splits_n &lt;- 21 splits_x &lt;- seq(-1, 1, length.out=splits_n) splits_y &lt;- apply(cbind(splits_x[1:(splits_n-1)], splits_x[2:splits_n]), 1, function(x){f(median(x))}) discretize_x &lt;- splits_x[c(1,1, rep(2:(splits_n-1), each=4), splits_n, splits_n)] discretize_y &lt;- as.vector(rbind(0, splits_y, splits_y, 0)) label &lt;- c(rep(&quot;f(x)&quot;, length(x)), rep(&quot;Discretized f(x)&quot;, length(discretize_x))) data.frame( x=c(x, discretize_x), y=c(y, discretize_y), f=factor(label, levels=c(&quot;f(x)&quot;, &quot;Discretized f(x)&quot;)) ) %&gt;% ggplot(aes(x=x, y=y, group=f)) + geom_line(aes(color=f)) Figure 1.1: pdf \\(f(x)\\)と離散化近似した関数 splits_n &lt;- 21 x &lt;- seq(-1, 1, length.out=splits_n) x &lt;- apply(cbind(x[1:(splits_n-1)], x[2:splits_n]), 1, median) y &lt;- f(x) data.frame( x = x, y = y ) %&gt;% ggplot(aes(x=x, y=y)) + geom_bar(stat = &quot;identity&quot;) Figure 1.2: \\(f(x)\\)を確率質量関数で近似した結果 "],["id_01-03-additve-and-multiplication-theorem.html", "1.3 加法定理・乗法定理", " 1.3 加法定理・乗法定理 確率変数\\(X, Y\\)を考え，それぞれ\\(\\Omega_X = \\{X_1, \\ldots, X_n\\}, \\Omega_Y = \\{Y_1, \\ldots, Y_n \\}\\)の中から実現値を得るものとする． この時\\(X_i, Y_j\\)を同時に取る確率を\\(p(X=X_i, Y=Y_j)\\)と表し，これを同時確率と呼ぶ． またこの分布\\(p(X,Y)\\)を同時分布と呼ぶ． \\[ \\sum_{x \\in \\Omega_X, y \\in \\Omega_Y} p(X=x, Y=x) \\] とできる時，確率変数\\(Y\\)については \\[ \\begin{align} p(Y) = \\sum_{x \\in \\Omega_X} p(X, Y) \\tag{1.1} \\end{align} \\] と表すことができる．また条件付き分布（conditional distribution）を \\[ \\begin{align} p(X|Y) = \\frac{p(X,Y)}{p(Y)} \\tag{1.2} \\end{align} \\] と表し，確率の乗法定理とも呼ばれる． 1.3.1 周辺化・周辺分布 加法定理を適用して同時分布である確率変数のみの分布を表現することを周辺化（marginalization）と呼ぶ．このようにして得られた分布を周辺分布などと呼ぶ． 1.3.2 連続値の場合 連続型の確率変数\\(x, y\\)についても加法定理と乗法定理は同様に考えることができる． \\[ \\begin{align} p(y) &amp;= \\int_{\\infty}^{-\\infty} p(x,y) dx \\\\ p(x|y) &amp;= {p(x,y) \\over p(y)} \\tag{1.3} \\end{align} \\] 1.3.3 ベイズの定理 乗法定理は確率変数を交換しても成立する． \\[\\begin{align} \\tag{1.4} p(x,y) = p(x|y)p(y) = p(y|x)p(x) \\end{align}\\] これよりベイズの定理と呼ばれる次式を得る． \\[\\begin{align} \\tag{1.5} p(x|y) = \\dfrac{p(y|x)p(x)}{p(y)} \\end{align}\\] ベイズの定理を用いて，ある確率分布の未知パラメータを観測データから推論することをベイズ推論（Bayesian inference）と呼ぶ． ここで，観測データを\\(\\mathcal D\\)，未知パラメータを\\(\\theta\\)としてベイズの定理に当てはめると \\[\\begin{align} \\tag{1.6} p(\\theta | \\mathcal D) = \\dfrac{p(\\mathcal D | \\theta)}{p(\\mathcal D)}p(\\theta) \\end{align}\\] となる．つまり求めたいのは\\(p(\\theta|\\mathcal D)\\)である． \\(p(\\cdot)\\) description \\(p(\\theta)\\) 事前分布 \\(p(\\theta|\\mathcal D)\\) 事後分布 \\(p(\\mathcal D | \\theta)\\) 尤度 \\(p(\\mathcal D)\\) 正規化定数．これは\\(p(\\mathcal D| \\theta)p(\\theta)\\)を周辺化して得られる． 推論においてはデータ\\(\\mathcal D\\)は所与のものと考えるので，\\(p(\\mathcal D)\\)は定数とみなせること，また確率変数\\(\\theta\\)の分布のみに興味があることを強調して \\[\\begin{align} \\tag{1.7} p(\\theta|\\mathcal D) \\propto p(\\mathcal D | \\theta) p(\\theta) \\end{align}\\] と表現することもある． "],["id_01-04-bayse-inference.html", "1.4 ベイズの定理を使ったクリック率の推論", " 1.4 ベイズの定理を使ったクリック率の推論 推論を実行する際に，最初にどのような事前分布を設定するかを考える必要がある．これは分析者次第となる．よく使われるものの一つとして無情報の事前分布といういみで一様分布を設定することがあり，ここではこれを採用する． \\(\\theta\\)はクリック率を表す確率変数であり，\\(\\theta \\in [0,1]\\)なので\\(U(0,1)\\)を設定しよう． \\[\\begin{align} \\tag{1.8} p(\\theta) = \\begin{cases} 1 &amp; 0 \\leq \\theta \\leq 1 \\\\ 0 &amp; \\text{else} \\end{cases} \\end{align}\\] さらにこの\\(\\theta\\)はクリック率を意味するので \\[\\begin{align} \\tag{1.9} \\text{Bernoulli}(\\theta) = \\theta^r(1-\\theta)^{(1-r)} \\end{align}\\] 推論を行うとき，パラメータが与えられた時の\\(r\\)が発生する条件付き確率から，データが与えられた時に\\(\\theta\\)を推定することと読み替えることになる． つまり\\(p(\\mathcal D|\\theta)\\)ではなく\\(p(\\theta|\\mathcal D)\\)を考える．これを尤度関数と呼び，一般には確率分布ではなくなる． scene &lt;- list( &quot;xaxis&quot; = list(title=&quot;r&quot;), &quot;yaxis&quot; = list(title=&quot;theta&quot;), &quot;zaxis&quot; = list(title=&quot;p(r|theta)&quot;) ) n &lt;- 300 r &lt;- c(0,1) theta &lt;- seq(0,1,length=n) z &lt;- expand.grid(r,theta) %&gt;% apply(1, function(e){ res &lt;- e[2]^{e[1]}*(1-e[2])^{1-e[1]} return(res) }) %&gt;% matrix(nrow=n, byrow=T) plot_ly(x=r, y=theta, z=z, hovertemplate = &quot;r: %{x}&lt;br&gt;theta: %{y}&lt;br&gt;p(r|theta): %{z}&quot;) %&gt;% plotly::add_surface() %&gt;% plotly::layout(scene=scene) Figure 1.3: ベルヌーイ分布の3D表現 \\(p(r|\\theta)\\)を尤度関数とみなす，つまり\\(r\\)を固定した時の\\(\\theta\\)の関数と考えた時，\\(r=1\\)であれば \\[\\begin{align} \\int_{0}^{1} \\theta^{r} (1-\\theta)^{1-r} d\\theta &amp;= \\begin{cases} \\int_{0}^{1} \\theta d\\theta, &amp; r=1 \\\\ \\int_{0}^{1} (1-\\theta) d\\theta, &amp; r=0 \\end{cases} \\\\ &amp;= \\dfrac12 \\end{align}\\] となる．全積分が1ではないため，確率分布ではないことがわかる． さてこれらの尤度関数と事前分布を@ref{eq:bayse-inference-with-propto}式に代入すると，\\(\\theta \\in [0,1]\\)の範囲において考えれば\\(p(\\theta)=1\\)なので \\[\\begin{align} p(\\theta | r) &amp;= \\propto p(r | \\theta) p(\\theta) \\\\ &amp;= \\theta^r(1-\\theta)^{1-r} \\end{align}\\] となる． 先ほどの議論と同様にこの関数は確率分布ではないため，事後分布とするために正規化定数\\(p(r)\\)で除する必要がある． \\[\\begin{align} p(r) &amp;= \\int_{-\\infty}^{\\infty} p(r|\\theta) p(\\theta) d \\theta \\\\ &amp;= \\int_0^1 \\theta^r (1-\\theta)^{(1-r)} d \\theta \\\\ &amp;= \\begin{cases} \\displaystyle \\int_0^1 (1-\\theta) d \\theta, &amp; r=0 \\\\ \\displaystyle \\int_0^1 \\theta d \\theta, &amp; r=1 \\end{cases} \\\\ &amp;= \\dfrac12 \\end{align}\\] であるので，結局事後分布は \\[\\begin{align} p(\\theta | r) &amp;= \\dfrac{p(r|\\theta)p(\\theta)}{p(r)} \\\\ &amp;= 2 \\theta^r (1-\\theta)^{(1-r)} \\end{align}\\] と求められる．これらを図示すれば att_labs &lt;- c(&quot;r=1&quot;, &quot;r=0&quot;) names(att_labs) &lt;- c(1,0) r &lt;- c(0,1) theta &lt;- seq(0,1,length=300) df &lt;- expand_grid(r, theta) %&gt;% mutate(v = 2*theta^r * (1-theta)^{1-r}) g &lt;- ggplot(data=df, aes(x=theta, y=v,group=r)) + geom_line() + facet_wrap(~r, labeller = labeller(r=att_labs)) plot(g) Figure 1.4: ベイズ推論によって得られた事後分布 以上は一回のデータ観測におけるベイズ推論であったが実際にはいくつかのデータが得られているはずで，その分推論を繰り返すことでデータ\\(\\mathcal D\\)が観測された元での事後分布を得ることができる．ただしこの時，各データは独立であるという過程が置かれている． "],["id_01-05-implementation-in-r.html", "1.5 Rでの実装", " 1.5 Rでの実装 前項の例におけるベイズ推論を実装してみよう．まず，\\(\\theta\\)の取りうる値のベクトルを作成する．必ずしも1001分割でなければいけないわけではない． \\[ \\tilde{\\boldsymbol \\theta} = (0, 0001, 0.002,\\ldots,0.999, 1) \\] thetas &lt;- seq(0, 1, length=1001) thetas %&gt;% head() ## [1] 0.000 0.001 0.002 0.003 0.004 0.005 次に，尤度関数を実装する．実現値\\(r=1\\)であればthetasを，\\(r=0\\)なら1-thetasを返す． \\[ p(\\theta|r) = \\theta^r (1-\\theta)^{1-r} \\] likelihood &lt;- function(r, thetas){ if(r){ return(thetas) }else{ return(1-thetas) } } 最後に事後分布を計算するposteriorを実装する． \\[ p(\\theta|r) = 2\\theta^r(1-\\theta)^{1-r} \\] posterior &lt;- function(r, prior, thetas){ lp = likelihood(r, thetas) * prior return(lp / sum(lp)) # 尤度関数と事前分布の積をその和で割って正規化しておく } ベイズ推論を行う前に，事前分布を作成しておこう．事前分布は一様分布としていたので以下のようになる． prior &lt;- rep(1/length(thetas), length(thetas)) ではベイズ推論を実行する． p &lt;- posterior(r=1, prior, thetas) tibble(thetas=thetas, p=p, prior=prior) %&gt;% pivot_longer(cols=c(p,prior), names_to=&quot;distribution&quot;, values_to=&quot;prob&quot;) %&gt;% ggplot(aes(x=thetas, y=prob, group=distribution, color=distribution)) + geom_line() さらに繰り返しベイズ推論を実行して変化を見てみよう．いま得られたデータとしてはクリックが2，でクリックなしが38だったので，この順番には意味がないとすれば以下のように実装できる． len_n &lt;- 1001 thetas &lt;- seq(0,1,length=len_n) click = c(rep(1,2), rep(0, 38)) p &lt;- rep(1/len_n, len_n) results &lt;- tibble( thetas=thetas, p=p, iteration=0 ) for(i in 1:length(click)){ r &lt;- click[i] p &lt;- posterior(r=r, prior=p, thetas=thetas) results &lt;- bind_rows( results, tibble( thetas=thetas, p=p, iteration=i ) ) } 事後分布の変化の様子をプロットしてみよう． max_value &lt;- results %&gt;% dplyr::filter(iteration==max(iteration), p==max(p)) %&gt;% pull(thetas) results %&gt;% ggplot(aes(x=thetas, y=p, group=iteration, color=iteration)) + geom_line() + geom_vline(xintercept=max_value, color=&quot;orange&quot;) Figure 1.5: ベイズ推論の繰り返しによる事後分布の変遷 最終的には0.05付近に最も大きな値をもつ事後分布が得られていることがわかる（黄色の縦線）． "],["id_01-06-bayse-inference-with-reports.html", "1.6 レポートデータを用いた推論", " 1.6 レポートデータを用いた推論 表 1.1 のデータに基づいたベイズ推論を実行してみよう． 簡単のため，さらにメタ的な関数を実装しておく． また繰り返しの回数が多くなるので，２項分布を用いた形に書き直しておこう． likelihood &lt;- function(x, n, thetas){ res &lt;- (thetas^{x}) * ((1-thetas)^{n-x}) return(res) } posterior &lt;- function(x, n, prior, thetas){ lp = likelihood(x, n, thetas) * prior return(lp / sum(lp)) # 尤度関数と事前分布の積をその和で割って正規化しておく } click_rate_inference &lt;- function(click, imp, prior_type=&quot;uniform&quot;, len_n=1001){ thetas &lt;- seq(0,1,length=len_n) if(prior_type==&quot;uniform&quot;){ p &lt;- rep(1/len_n, len_n) } p &lt;- posterior(x=click, n=imp, prior=p, thetas=thetas) results &lt;- tibble( thetas=thetas, p=p ) return(results) } では，AliceとBobの二つのデザインについての結果を用いて推論を実行してみよう． reports &lt;- list( &quot;Alice-A&quot; = list(name=&quot;Alice&quot;, type=&quot;A&quot;, imp=40, click=2), &quot;Alice-B&quot; = list(name=&quot;Alice&quot;, type=&quot;B&quot;, imp=50, click=4), &quot;Bob-A&quot; = list(name=&quot;Bob&quot;, type=&quot;A&quot;, imp=1280, click=64), &quot;Bob-B&quot; = list(name=&quot;Bob&quot;, type=&quot;B&quot;, imp=1600, click=128) ) results &lt;- lapply(reports, function(e){ res &lt;- click_rate_inference(imp=e$imp, click=e$click) res$name &lt;- e$name res$type &lt;- e$type return(res) }) %&gt;% bind_rows() AliceとBobそれぞれについて事後分布を可視化してみよう． results %&gt;% dplyr::filter(thetas &lt; 0.3) %&gt;% # 0.3以上はほとんど0なので除く ggplot(aes(x=thetas, y=p, group=type, color=type)) + geom_line() + facet_wrap(~name, scales = &quot;free_y&quot;, nrow = 2) Figure 1.6: AliceとBobのレポートのベイズ推論 単純な集計では，AliceとBobのレポートではクリック率がA,Bで同じだったが，今回の推論による事後分布を見ると，より多くのデータを獲得できたBobの結果の方がより確信度が高いことがわかる．Aliceの方は分布の裾が大きいため，クリック率についての確信度はBobよりも高くない． "],["id_01-06-02-beta-distribution.html", "1.7 別解:ベータ分布", " 1.7 別解:ベータ分布 ベルヌーイ分布の尤度関数\\(\\theta^r (1-\\theta)^{1-r}\\)を繰り返し掛けていく操作は一般化すると \\[\\begin{align} \\tag{1.10} p(\\theta | a,N) = \\dfrac{\\theta^{a} (1-\\theta)^{N-a}}{\\int_{0}^{1} \\theta^{a}(1-\\theta)^{N-a} d \\theta} \\end{align}\\] と表せる．これはベータ分布と一致する．一般的にはベータ分布の確率密度関数は\\(\\alpha &gt;0, \\beta &gt; 0\\)をパラメータとして以下のように表される \\[\\begin{align} \\tag{1.11} \\text{Beta}(\\alpha, \\beta) = p(\\theta | \\alpha, \\beta) = \\dfrac{\\theta^{\\alpha - 1} (1-\\theta)^{\\beta - 1}}{\\int_{0}^{1} \\theta^{\\alpha - 1}(1-\\theta)^{\\beta - 1} d \\theta} \\end{align}\\] \\(\\alpha, \\beta\\)の値を変えた場合のベータ分布の形状をプロットしてみよう． thetas &lt;- seq(0.001, 0.999,length=1000) params &lt;- matrix(c(1,2,0.5,1,5,0.5), byrow=T, nrow=2) apply(params, 2, function(e){ dbeta(thetas, e[1], e[2]) }) %&gt;% as_tibble() %&gt;% rename( alpha_1_beta_1 = V1, alpha_2_beta_5 = V2, alpha_05_beta_05 = V3 ) %&gt;% bind_cols(thetas=thetas) %&gt;% pivot_longer(cols=c(&quot;alpha_1_beta_1&quot;,&quot;alpha_2_beta_5&quot;,&quot;alpha_05_beta_05&quot;), values_to = &quot;dbeta&quot;, names_to = &quot;params&quot;) %&gt;% dplyr::filter(dbeta &lt; 3) %&gt;% ggplot(aes(x=thetas, y=dbeta, group=params)) + geom_line(aes(color=params)) Figure 1.7: ベータ分布の形状 一般に事前分布と事後分布が同じ確率分布で表せるとは限らないが，ある尤度関数について，事後分布と事前分布が同じ種類の確率分布で表される特徴を持つ事前分布のことを共役事前分布(conjugate prior)と呼ぶ． この例では，事後分布が\\(\\alpha = a + 1, \\beta = N - a + 1\\)としたベータ分布として表される． thetas &lt;- seq(0.001, 0.999,length=1000) beta_pdf &lt;- function(alpha, beta, thetas){ numerator &lt;- thetas ** (alpha - 1) * (1 - thetas) ** (beta - 1) return(numerator / sum(numerator)) } beta_posterior &lt;- function(a, N, thetas){ return(beta_pdf(a + 1, N - a + 1, thetas)) } reports &lt;- list( &quot;Alice-A&quot; = list(name=&quot;Alice&quot;, type=&quot;A&quot;, imp=40, click=2), &quot;Alice-B&quot; = list(name=&quot;Alice&quot;, type=&quot;B&quot;, imp=50, click=4), &quot;Bob-A&quot; = list(name=&quot;Bob&quot;, type=&quot;A&quot;, imp=1280, click=64), &quot;Bob-B&quot; = list(name=&quot;Bob&quot;, type=&quot;B&quot;, imp=1600, click=128) ) results &lt;- lapply(reports, function(e){ thetas &lt;- seq(0,1,length=1001) p &lt;- beta_posterior(e$click, e$imp, thetas) res &lt;- tibble( thetas=thetas, p=p ) res$name &lt;- e$name res$type &lt;- e$type return(res) }) %&gt;% bind_rows() results %&gt;% dplyr::filter(thetas &lt; 0.3) %&gt;% # 0.3以上はほとんど0なので除く ggplot(aes(x=thetas, y=p, group=type, color=type)) + geom_line() + facet_wrap(~name, scales = &quot;free_y&quot;, nrow = 2) Figure 1.8: ベータ分布で表現した場合の推論結果 以上のように，ベータ分布の形で描き下しても変わらないことが確認できた． "],["id_01-07-decision-making.html", "1.8 事後分布から決断を下す", " 1.8 事後分布から決断を下す ベイズ推論で得られた事後分布の特徴を数値化したり，事後分布からのサンプルを利用することで意思決定に有用な情報を得ることができる． 1.8.1 要約統計量 Definition 1.1 (期待値) 連続・離散の確率分布に対して期待値をそれぞれ以下のように定義する． \\[\\begin{align} E[x] = \\begin{cases} \\int_{-\\infty}^{\\infty} xp(x) dx, &amp; \\text{continuous} \\sum{x} x p(x), &amp; \\text{discrete} \\end{cases} \\end{align}\\] Definition 1.2 (分散) 分散は次のように定義される． \\[\\begin{align} V[x] = E[(x-E[x])^2] \\end{align}\\] また\\(\\sqrt{V[x]}\\)を標準偏差と呼ぶ． Definition 1.3 (標本平均・標本分散) 確率分布から得られたサンプルに対して，その平均\\(\\bar x\\)と分散\\(s^2\\)を次のように定義する．これらはそれぞれ標本平均・標本分散と呼ぶ． \\[\\begin{align} \\bar x &amp;= \\dfrac{1}{n}\\sum_{i=1}^{n} x_i \\\\ s^2 &amp;= \\dfrac1n \\sum_{i=1}^{n} (x_i - \\bar x)^2 \\end{align}\\] 標本平均については，サンプルが独立で同一の分布に従う(independent identity distribution)とき，\\(n \\rightarrow \\infty\\)で分布の期待値に収束することが知られている（大数の法則）． これを \\[\\begin{align} \\bar x \\longrightarrow E[x] \\ (n \\rightarrow \\infty) \\end{align}\\] と表す． Definition 1.4 (HDI:highest density interval) 連続型の確率分布に対して，以下のように定義される量をHDI(highest density interval)と呼ぶ． \\[\\begin{align} \\int_{p(x)&gt;t} p(x) dx = \\dfrac{\\alpha}{100} \\end{align}\\] ここで\\(t\\)は閾値でこの値よりも確率密度が高い区間で埋めていって\\(\\alpha\\)に一致する点となる． HDIは確率変数の値が高い確率で現れる区間を表していて，例えば\\(\\alpha = 0.95\\)のとき95%HDIと呼ばれ，確率\\(0.95\\)を占めるまでの確率密度が高いものから埋めて行った区域となる． 確率分布が複数の山（ピーク）を持つ場合，HDIは複数の区域に分かれることがある． 1.8.2 HDIをつかった仮設検定 本来連続型の確率分布に対して定義されているHDIだが，同様の考え方を用いで離散型の確率分布にも適用してみよう． ここでは，確率質量が多い確率変数の値を順に追加していく，という操作をする． hmv &lt;- function(xs, ps, alpha=0.95){ df &lt;- tibble(xs=xs, ps=ps) %&gt;% dplyr::arrange(desc(ps)) %&gt;% mutate(cumsum_ps = cumsum(ps)) hmv_range &lt;- df %&gt;% dplyr::filter(cumsum_ps &lt;= alpha) %&gt;% pull(xs) %&gt;% range() res &lt;- list( range=hmv_range, x=df ) return(res) } # AliceのA案の結果についてhmvを計算する Alice_A &lt;- results %&gt;% dplyr::filter( name == &quot;Alice&quot;, type == &quot;A&quot; ) hmv_Alice_a &lt;- hmv(xs=Alice_A$thetas, ps=Alice_A$p) hmv_Alice_a$range ## [1] 0.009 0.148 plots &lt;- list() i &lt;- 1 hdi_summary &lt;- tibble() for(tgt_name in c(&quot;Alice&quot;, &quot;Bob&quot;)){ for(tgt_type in c(&quot;A&quot;, &quot;B&quot;)){ df &lt;- results %&gt;% dplyr::filter( name == tgt_name, type == tgt_type ) fill_range &lt;- hmv(xs=df$thetas, ps=df$p)$range hdi_summary &lt;- bind_rows( hdi_summary, tibble(name=tgt_name, type=tgt_name, hid_min=fill_range[1], hdi_max=fill_range[2]) ) bounds &lt;- df %&gt;% dplyr::filter( thetas &gt; fill_range[1], thetas &lt; fill_range[2] ) plots[[i]] &lt;- df %&gt;% dplyr::filter(thetas &lt; 0.3) %&gt;% ggplot(aes(x=thetas, y=p)) + geom_line() + geom_ribbon(data=bounds, aes(ymax=p), ymin=0, fill=&quot;orange&quot;, alpha=0.5) + ggtitle(label=glue(&quot;{tgt_name} - {tgt_type}&quot;), subtitle = glue(&quot;HDI: [{fill_range[1]}, {fill_range[2]}]&quot;)) i &lt;- i+1 } } gridExtra::grid.arrange( plots[[1]],plots[[3]],plots[[2]],plots[[4]], nrow=2, ncol=2 ) Figure 1.9: 事後分布とHDI 図1.9をみると，Bobの方がHDIの範囲が小さいことがわかる． どちらもB案の方が事後分布が右によっているものの，Aliceの方はHDIの重なる領域が多く，Bobは重なっていない． ここから以下の仮説を検証してみよう． 仮説：デザインB案のクリック率はよりも5%大きい． 一般的には95%HDIを仮設検定に利用することが多い．ただしこの閾値は分析者によって決定されるものでありそれはチームで合意を取るべき数値である． さて，HDIのサマリである表1.2を見るとAlice-BのHDIは\\([0.026, 0.175]\\)，Bob-Bは\\([0.068, 0.093]\\)であり，5%が含まれているのはAlice-Bである．これより，Alice-Bについては仮説が成り立つとは言えず，Bob-Bは成り立っていると言えるだろう． knitr::kable(hdi_summary, label = &quot;hdi-summary-1&quot;, caption = &quot;Alice，BobそれぞれのHDIの範囲&quot;) Table 1.2: Alice，BobそれぞれのHDIの範囲 name type hid_min hdi_max Alice Alice 0.009 0.148 Alice Alice 0.026 0.175 Bob Bob 0.040 0.062 Bob Bob 0.068 0.093 例えば，HDIが\\([0.051,0.06]\\)のような値だった場合に今回の仮説を採択すべきかについては，難しい問題である． 閾値を厳密なものとして運用するか，ある程度許容する幅を持たせるかも分析の設計次第であり，チームで合意しておく必要はある． 例えば閾値を\\([0.45, 0.55]\\)のように設定する場合，この区間をROPE(region of practical equivalence)という． ROPEを利用する際の意思決定については以下のようなルールが考えられる． \\(\\text{ROPE} \\not\\subset \\text{HDI}\\)は仮説を棄却 \\(\\text{HDI} \\subset \\text{ROPE}\\)は仮説を採択 そのほかの場合は結論づけることを控える 今度は以下のような仮説を考えてみよう． 仮説：デザインB案はデザインA案よりも大きい これはHDIを利用する場合は以下のように運用することができる． デザインB案の95%HDIがデザインA案のHDIが互いに素なとき，2つのクリックは異なる． \\(\\forall a \\in \\text{HDI}_A, \\forall b \\in \\text{HDI}_B \\Rightarrow a &lt; b\\)が成り立つ時，B案の値はA案よりも大きい \\(\\forall a \\in \\text{HDI}_A, \\forall b \\in \\text{HDI}_B \\Rightarrow a &gt; b\\)が成り立つ時，B案の値はA案よりも小さい その他の場合は結論づけることを控える． この仮説ではAliceの場合はHDIの領域に被りがあるためクリック率の大小について結論づけることはできないとし，Bobの場合はB案の方が大きいと結論づけられる． "],["id_01-08-introduce-new-random-variable.html", "1.9 新たな確率変数を導入する", " 1.9 新たな確率変数を導入する 事後分布を得た確率変数を変換して，新たな確率変数を得てその分布に着目することを考えよう． 仮説：デザインB案のクリック率はデザインA案よりも大きい この仮説は\\(\\delta &gt; \\theta_B - \\theta_A\\)であり\\(\\delta\\)が新たな確率変数となる．\\(\\delta\\)の分布については，A,Bそれぞれの事後分布に基づいて乱数を発生させて\\(\\delta\\)のサンプルを得ることで，標本から分布を推定することにする． それぞれの事後分布は，上記の議論の中で以下のパラメータを持つベータ分布で表せるので，ここからサンプルを生成すればよい． Name Type \\(\\alpha = a + 1\\) \\(\\beta = N - a + 1\\) Alice A 3 39 B 5 47 Bob A 65 1,217 B 129 1,473 rdelta &lt;- function(n, params) { # params: list of parameters for 2 beta-distribution # params &lt;- list(A = list(alpha, beta), B = list(alpha, beta)) A &lt;- rbeta(n=n, shape1=params$A$alpha, shape2=params$A$beta) B &lt;- rbeta(n=n, shape1=params$B$alpha, shape2=params$B$beta) delta &lt;- B - A res &lt;- tibble(A=A, B=B, delta=delta) return(res) } Alice_params &lt;- list( A = list(alpha=3, beta=39), B = list(alpha=5, beta=47) ) Bob_params &lt;- list( A = list(alpha=65, beta=1217), B = list(alpha=129, beta=1473) ) set.seed(777) vis_data &lt;- bind_rows( rdelta(n=100000, params=Alice_params) %&gt;% mutate(name=&quot;Alice&quot;), rdelta(n=100000, params=Bob_params) %&gt;% mutate(name=&quot;Bob&quot;) ) ggplot(vis_data, aes(delta)) + geom_histogram(binwidth = 0.01) + facet_wrap(~name, scales = &quot;free_y&quot;) Figure 1.10: deltaの差のヒストグラム 図 1.10 はAlice，Bobそれぞれの事後分布から生成したサンプルもとにした\\(\\delta\\)のヒストグラムである． この\\(\\delta\\)のサンプルに対して以下のような仮説を立てて検証することができる． 仮説：\\(\\delta\\)が95%で正の値になる． 具体的には，生成した\\(\\delta\\)のサンプルが正の値になっている割合を計算すれば良い． hypo_summary &lt;- vis_data %&gt;% mutate(hypo_test = delta &gt; 0) %&gt;% group_by(name) %&gt;% summarise(n=n(), hypo=mean(hypo_test)) knitr::kable(hypo_summary, label = &quot;delta-hypo-summary&quot;, caption = &quot;δ&gt;0の割合&quot;) Table 1.3: δ&gt;0の割合 name n hypo Alice 1e+05 0.68209 Bob 1e+05 0.99940 表1.3がAlice，Bobそれぞれの\\(\\delta &gt; 0\\)の割合である．これより，Aliceについては仮説を採択できず，Bobについては仮説が正しいと結論づける根拠にできると考えられる． "],["id_02-00-00-inference-with-rstan.html", "2 RStanを使った推論", " 2 RStanを使った推論 1章では事前分布の設定，事後分布の導出からサンプル生成までを実装した上でおこなっていだが， 複雑なモデリングの場合は実装が難しい場合もある． ここからはベイズ推論のためのフレームワークStanをRから呼び出せるRStanを利用した推論を行なっていく． あらかじめ公式ドキュメントを参考に必要に応じてRstanをインストールしておくこと． "],["id_02-02-00-review-score.html", "2.1 真のレビュースコア", " 2.1 真のレビュースコア レビューのスコアについてベイス推定を行う．ここでは次のTable 2.1 のデータが得られているとして進めていく． review_score &lt;- tibble( item = rep(c(&#39;A&#39;, &#39;B&#39;), each = 5), score = base::rep(1:5, times = 2), count = c(20, 10, 36, 91, 170, 0, 0, 4, 0, 6) ) review_score %&gt;% pivot_wider(names_from = &quot;score&quot;, values_from = &quot;count&quot;) %&gt;% knitr::kable(caption = &quot;仮想のレビュースコアのデータ&quot;, label = &quot;data-review-score&quot;) %&gt;% kableExtra::kable_styling(full_width = FALSE) Table 2.1: 仮想のレビュースコアのデータ item 1 2 3 4 5 A 20 10 36 91 170 B 0 0 4 0 6 これらのレビューについて回答数と平均点を計算するとTable 2.2 のようになる． Table 2.2: レビュースコアのアイテムごとの回答人数と平均 item total_count mean A 327 4.165138 B 10 4.200000 平均点を見るとどちらも同じ位でかつBの方が若干高い．しかし回答数をみるとAの方が信頼できそうに思える． このデータについては複数の値を取るカテゴリデータと見做してモデルを式 (2.1) のように考えよう． \\[\\begin{align} \\begin{aligned} \\boldsymbol\\theta &amp;\\sim \\text{Dirichlet}(\\boldsymbol\\alpha) \\\\ \\boldsymbol r &amp;\\sim \\text{Categorical}(\\boldsymbol\\theta) \\end{aligned} \\tag{2.1} \\end{align}\\] ディリクレ分布は\\(K\\)次元で，要素が\\([0,1]\\)の値を取り，その総和が\\(1\\)となるような確率変数ベクトルが従う確率分布である．ディリクレ分布自体はパラメータとして\\(K\\)次元ベクトル\\(\\boldsymbol \\alpha\\)を取る． 2.1.1 ディリクレ分布による事前分布 ここで事前分布には簡単のため以下の式 (2.2) を採用しよう． \\[\\begin{align} \\begin{aligned} \\boldsymbol\\theta &amp;\\sim \\text{Dirichlet}(\\boldsymbol\\alpha = (1,1,1,1,1)) \\\\ \\boldsymbol r &amp;\\sim \\text{Categorical}(\\boldsymbol\\theta) \\end{aligned} \\tag{2.2} \\end{align}\\] 2.1.2 推論の実行 RStanでこのモデルについてMCMCを行い事後分布を推定する．stanのコードは次のようになる． data { int n; int&lt;lower=1&gt; n_category; int&lt;lower=0&gt; counts[n]; vector&lt;lower=0&gt;[n_category] alpha; } parameters { simplex[n_category] theta; } model { theta ~ dirichlet(alpha); counts ~ multinomial(theta); } このstanコードを実行して結果を得よう． # item A について多項分布・ディリクレ分布によるベイズ推論を行う df %&gt;% dplyr::filter(item == &quot;A&quot;) n_category &lt;- 5 # カテゴリ数 counts &lt;- df$count # レビュースコアのカウント alphas &lt;- c(1,1,1,1,1) # ディリクレ分布のパラメーター review_data &lt;- list( n_category = n_category, counts = counts, alpha = alpha ) # stanの実行 model_path &lt;- &quot;[path to the stan file]&quot; seed = 1234 fit_item_a &lt;- rstan::stan( file = model_path, data = review_data, seed = seed, iter = 4000, chain = 4, control = list( max_treedepth = 15 ) ) 推定結果は 2.3 のようになった． Table 2.3: Item Aのレビューに対するベイズ推論の結果 mean se_mean sd 2.5% 50% 97.5% Rhat 0.063 0 0.013 0.040 0.062 0.093 1.000 0.033 0 0.010 0.017 0.032 0.055 1.000 0.111 0 0.017 0.080 0.111 0.147 1.000 0.277 0 0.024 0.230 0.277 0.326 1.000 0.515 0 0.028 0.460 0.515 0.569 1.001 ms_a &lt;- rstan::extract(fit_item_a) ms_a$theta %&gt;% tidyr::as_tibble(.name_repair = &quot;unique&quot;) %&gt;% magrittr::set_colnames(paste(&quot;theta&quot;, 1:5, sep=&quot;_&quot;)) %&gt;% tidyr::pivot_longer(cols=everything(), names_to = &quot;theta&quot;, values_to = &quot;sample&quot;) %&gt;% ggplot() + geom_density(aes(x = sample), fill = &quot;blue&quot;, alpha = 0.4) + facet_wrap(~theta) Figure 2.1: Item Aにおける多項分布のパラメータの事後分布 いまレビューの平均スコアを式 (2.3) のように定義すると \\[\\begin{align} m = 1 \\theta_1 + 2 \\theta_2 + 3 \\theta_3 + 4 \\theta_4 + 5 \\theta_5 \\tag{2.3} \\end{align}\\] この確率変数に対してMCMCのサンプルを用いて事後分布を求めることができる． posterior_avg &lt;- ms_a$theta %*% 1:5 above4_a &lt;- round(mean(posterior_avg &gt; 4), 3) subtitle &lt;- glue::glue(&quot;proportion of &gt; 4 = {above4_a}&quot;) posterior_avg %&gt;% tidyr::as_tibble() %&gt;% ggplot() + geom_density(aes(x = V1), fill = &quot;blue&quot;, alpha = 0.4) + xlim(0, 5) + ggtitle(label = &quot;Posterior distribution of Average: Item A&quot;, subtitle = subtitle) -&gt; pa_avg pa_avg Figure 2.2: Item Aの平均レビュースコアの事後分布 この事後分布に対して，例えば平均のスコアが4以上になる割合は0.99と非常に高く，少なくとも4以上であることは信頼できそうである． 2.1.3 Item Bについての推論 全く同様の手続きで，Item Bについても推論を行なってみよう． モデルは同じなので渡すデータだけ変更すれば良い． df &lt;- review_score %&gt;% dplyr::filter(item == &quot;B&quot;) data_item_b &lt;- list( n_category = 5, counts = df$count, alpha = c(1,1,1,1,1) # 事前分布のパラメーター ) fit_item_b &lt;- rstan::stan( file = &quot;book/script/chapter02/stan/review-score-01.stan&quot;, data = data_item_b, seed = 1234, iter = 4000, chain = 4, control = list(max_treedepth = 15) ) Item Aと同様に推論の結果と事後分布を可視化しておく． summary(fit_item_b)$summary %&gt;% as.data.frame() %&gt;% rownames_to_column() %&gt;% as_tibble() %&gt;% dplyr::filter(rowname != &quot;lp__&quot;) %&gt;% select(mean, se_mean, sd, `2.5%`, `50%`, `97.5%`, Rhat) %&gt;% round(3) %&gt;% knitr::kable(caption = &quot;Item Bのレビューに対するベイズ推論の結果&quot;, label = &quot;stan-result-item-b&quot;) Table 2.4: Item Bのレビューに対するベイズ推論の結果 mean se_mean sd 2.5% 50% 97.5% Rhat 0.067 0.001 0.064 0.002 0.048 0.240 1 0.067 0.001 0.063 0.002 0.048 0.238 1 0.334 0.001 0.117 0.133 0.325 0.581 1 0.066 0.001 0.062 0.002 0.048 0.228 1 0.465 0.001 0.123 0.232 0.464 0.705 1 ms_b &lt;- rstan::extract(fit_item_b) ms_b$theta %&gt;% tidyr::as_tibble(.name_repair = &quot;unique&quot;) %&gt;% magrittr::set_colnames(paste(&quot;theta&quot;, 1:5, sep=&quot;_&quot;)) %&gt;% tidyr::pivot_longer(cols=everything(), names_to = &quot;theta&quot;, values_to = &quot;sample&quot;) %&gt;% ggplot() + geom_density(aes(x = sample), fill = &quot;orange&quot;, alpha = 0.4) + facet_wrap(~theta) Figure 2.3: Item Bにおける多項分布のパラメータの事後分布 posterior_avg &lt;- ms_b$theta %*% 1:5 above4_a &lt;- round(mean(posterior_avg &gt; 4), 3) subtitle &lt;- glue::glue(&quot;proportion of &gt; 4 = {above4_a}&quot;) posterior_avg %&gt;% tidyr::as_tibble() %&gt;% ggplot() + geom_density(aes(x = V1), fill = &quot;orange&quot;, alpha = 0.4) + xlim(0, 5) + ggtitle(label = &quot;Posterior distribution of Average: Item B&quot;, subtitle = subtitle) -&gt; pb_avg pb_avg Figure 2.4: Item Bの平均レビュースコアの事後分布 これらを確認すると，Item Bの方はItem Aに比べて事後分布の形状がやや広いことがわかる． これは回答数が少ないため信頼区間が広くとられていると解釈できる． 2.1.4 推定結果の比較 最後にItem AとItem Bについて比較をまとめておこう． Fig 2.5 は既に示した図を縦に並べたものだが この比較で平均レビュースコアがどの程度信頼できるものかを確認できる． 量的に表す場合，例えば事後分布のサンプルが4以上であるものの割合を計算すれば ある意味で平均のスコアが4以上になる確率を推論することができる． その意味ではItem Aでは事後分布上で4以上となるものは0.987であり少なくとも4以上であるという ことはかなり信頼を持って言えそうだ． 一方Item Bでは0.268でありこの商品の平均レビュースコアが少なくとも4以上であるということの 信頼性は低いと思える． Figure 2.5: 平均レビュースコアの事後分布の比較 次に，Figure @ref(fig:spread_draws-of-items) はthetaの事後分布を比較した図である． Item Aの場合，thetaの事後分布の幅が比較的狭くなっておりレビューにおけるそれぞれのスコアで 評価される確率のブレが少ない一方，Item Bの場合は幅が広くブレが大きいことがわかる． 特に3と5は広く出ており現時点での平均スコアが4.2という値の信頼性が低いと見做せる． (#fig:spread_draws-of-items)thetaの事後分布の比較 最後にTable 2.5 はthetaの事後分布におけるHDIを比較した表である． HDIの値を確認することでも，事後分布がどれほどの幅を持っているのかを見ることができる． Table 2.5: Itemごとのthetaの事後分布における95%HDI theta Item A Item B 1 [0.038 - 0.09] (0.052) [0 - 0.193] (0.193) 2 [0.015 - 0.053] (0.038) [0 - 0.194] (0.194) 3 [0.08 - 0.146] (0.066) [0.118 - 0.557] (0.439) 4 [0.228 - 0.323] (0.095) [0 - 0.191] (0.191) 5 [0.462 - 0.57] (0.108) [0.229 - 0.7] (0.471) "],["id_02-03-00-visit-time.html", "2.2 滞在時間をテストする", " 2.2 滞在時間をテストする ここでは連続値の指標に対して仮設検定をしたい場合を扱っていく．例えば ウェブサイトに滞在した秒数 画面の表示領域に入ったウェブサイトのコンテンツの割合 などが考えられる．特にここでは後者を扱う．データについて以下のURLのものを使う． url &lt;- &quot;https://www.oreilly.co.jp/pub/9784873119168/data/time-on-page.csv&quot; time_on_page &lt;- read.csv(url) %&gt;% tidyr::as_tibble() %&gt;% magrittr::set_colnames(&quot;time_on_page&quot;) str(time_on_page) ## tibble [222 × 1] (S3: tbl_df/tbl/data.frame) ## $ time_on_page: int [1:222] 178 4 112 576 419 41 93 10 59 87 ... このデータセットは１列しかなく，一つのレコードが一回のアクセスの滞在時間となっている． このデータの分布のヒストグラムがFig 2.6 である． 裾が重い分布になっていて異常に大きな値があることがわかる． time_on_page %&gt;% ggplot() + geom_histogram(aes(x = time_on_page), binwidth = 30) Figure 2.6: アクセスごとの滞在時間のヒストグラム このような分布は中央値と平均に乖離が大きいことが多い，実際 time_on_page %&gt;% dplyr::reframe(n = n(), mean = mean(time_on_page), median = median(time_on_page), sd = sd(time_on_page)) %&gt;% knitr::kable( caption = &quot;time_on_pageの要約統計量&quot;, label = &quot;summary-of-time-on-page&quot; ) %&gt;% kableExtra::kable_styling(full_width = FALSE) Table 2.6: time_on_pageの要約統計量 n mean median sd 222 202.3333 78 343.2041 ここでは，滞在時間がパラメータ\\(\\theta\\)の指数分布に従うとして，ベイズ推論を行う． \\(\\theta\\)の事前分布としては無情報の事前分布の意味で一様分布を採用する． パラメータ\\(\\theta\\)の指数分布とは以下の確率密度関数を持つ確率分布である． \\[\\begin{align} p(x|\\theta) = \\dfrac{\\exp(-x/\\theta)}{\\theta} \\tag{2.4} \\end{align}\\] また，モデルとしては以下を考えることになる． \\[\\begin{align} \\begin{aligned} \\theta &amp;\\sim \\text{Uniform}(0, 3000) \\\\ t &amp;\\sim \\text{Exponential}(\\theta) \\end{aligned} \\tag{2.5} \\end{align}\\] 2.2.1 Stanでの推定 以下のスクリプトで，ベイス推論を実行した． data { int N; int &lt;lower=0&gt; time_on_page[N]; } parameters { real &lt;lower=0, upper=3000&gt; theta; } model { // prior theta ~ uniform(0, 3000); // likelihood for (n in 1:N) { time_on_page[n] ~ exponential(theta); } } url &lt;- &quot;https://www.oreilly.co.jp/pub/9784873119168/data/time-on-page.csv&quot; time_on_page &lt;- read.csv(url) %&gt;% tidyr::as_tibble() %&gt;% magrittr::set_colnames(&quot;time_on_page&quot;) data &lt;- list( N = nrow(time_on_page), time_on_page = time_on_page$time_on_page ) fit_time_on_page &lt;- rstan::stan( file = &quot;book/script/chapter02/stan/time-on-page-01.stan&quot;, data = data, seed = 1234, iter = 2000, chain = 4 ) Figure 2.7 を見ると，パラメータ\\(\\theta\\)の推定は問題なく収束していると判断できる． fit_time_on_page &lt;- readRDS(&quot;script/chapter02/stan/time-on-page-01.obj&quot;) stan_results &lt;- ggmcmc::ggs(fit_time_on_page) ggmcmc::ggs_traceplot(stan_results) Figure 2.7: thetaについてのMCMCのトレースプロット 次に事後分布を可視化してみる．Figure 2.8 が\\(\\theta\\)の事後分布である． 200付近を中心に裾が概ね\\(\\pm 50\\)程度に収まっている． ms &lt;- rstan::extract(fit_time_on_page) {1/ms$theta} %&gt;% tibble::as_tibble_col( column_name = &quot;sample-of-theta&quot; ) %&gt;% ggplot() + geom_density(aes(x = `sample-of-theta`), fill = &quot;blue&quot;, alpha = 0.4) Figure 2.8: 推定されたthetaの事後分布 fit_time_on_page %&gt;% rstan::extract() %&gt;% purrr::pluck(&quot;theta&quot;) %&gt;% {1/.} %&gt;% # 1/thetaを計算 tidybayes::hdi(ci = 0.95) %&gt;% # 95%HDI round(3) %&gt;% as.data.frame() %&gt;% magrittr::set_colnames(c(&quot;lower&quot;, &quot;upper&quot;)) %&gt;% knitr::kable( caption = &quot;thetaの事後分布におけるHDI&quot;, label = &quot;hdi-time-on-page&quot; ) Table 2.7: thetaの事後分布におけるHDI lower upper 175.052 230.135 Table 2.7 が95%HDIの計算結果である．滞在時間の平均は175 ~ 230程度と判断できる． 実際はデータの分布を見た通り多くのユーザーはもっと少ない滞在時間となっているが，あくまで平均の推定値としては この程度であるということになる． "],["id_03-00-00-test-with-combinations.html", "3 組み合わせのあるテスト", " 3 組み合わせのあるテスト 一般にウェブサイトでは写真・テキスト・ボタンなどの要素の集合であり それぞれが同時にユーザーに影響を与えているはずだ． このような場合において，扱いたい要素それぞれの影響を考慮した分析・A/Bテストが必要になる． ここではこのテーマを扱っていこう． "],["id_03-01-00-sample-report.html", "3.1 サンプルレポート", " 3.1 サンプルレポート まず以下のような状況を考えよう． ある商品のプロモーションのためにLPを作成した LPのデザインパターンとして以下を作成した ヒーローバナーを２パターン ボタンの文言を２パターン これらのデザインをそれぞれ無作為にユーザーに表示させてデータを収集した この実験によって得られたデータが以下のようなものだったとする． test_results &lt;- read_csv(&quot;dataset/chapter03/test-results.csv&quot;) ## Rows: 4 Columns: 4 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): pattern ## dbl (3): imp, click, ctr ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. test_results %&gt;% mutate(ctr = round(ctr, 4)) %&gt;% knitr::kable( caption = &quot;LPのデザイン表示テスト結果&quot;, label = &quot;sample-data-chapter-03&quot; ) %&gt;% kableExtra::kable_styling(full_width = FALSE) Table 3.1: LPのデザイン表示テスト結果 pattern imp click ctr A 434 8 0.0184 B 382 17 0.0445 C 394 10 0.0254 D 88 4 0.0455 3.1 を見るとパターンDの表示回数が少なくなっている．これは表示のロジックにバグがあったためということにしておく． 均等配信ができなかった状態で議論を進めていこう． 3.1.1 シンプルなベイズ推論 要素については一度忘れて既にやった通り表示とクリック数で二項分布を当てはめるベイズ推論を行ってみよう． つまりEquation (3.1) のようなモデルを考える． \\[\\begin{align} \\begin{aligned} \\text{Click} \\sim \\text{Binomial}(Impression, \\theta) \\end{aligned} \\tag{3.1} \\end{align}\\] Stanのコードはこのようになる． data { int N; int&lt;lower=0&gt; imp[N]; int&lt;lower=0&gt; click[N]; } parameters { real&lt;lower=0, upper=1&gt; theta[N] ; } model { for (n in 1:N) { click[n] ~ binomial(imp[n], theta[n]); } } Rの実行コードは以下のようにした． df &lt;- test_results data &lt;- list( N = nrow(df), imp = df$imp, click = df$click ) fit_simple_model &lt;- rstan::stan( file = model_path, data = data, iter = 4000, chain = 4, seed = 1234 ) トレースプロット Figure 3.1 を確認すると，問題なく収束していることが確認できる． ggmcmc::ggs(fit_simple_model) %&gt;% ggmcmc::ggs_traceplot() Figure 3.1: thetaのMCMCのトレースプロット 次に推定された事後分布とその要約を確認しておこう．これらをTable 3.2 にまとめる． Table 3.2: thetaの事後分布の要約 parameter mean sd lower upper hid_range theta_A 0.021 0.007 0.008 0.034 0.026 theta_B 0.047 0.011 0.026 0.068 0.042 theta_C 0.028 0.008 0.013 0.044 0.031 theta_D 0.055 0.024 0.014 0.104 0.090 また，事後分布の形状をFigure 3.2 にまとめた． fit_simple_model %&gt;% tidybayes::spread_draws(theta[condition]) %&gt;% mutate( condition = as.factor(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)[condition]) ) %&gt;% ggplot(aes(y = fct_rev(condition), x = theta),) + tidybayes::stat_halfeye(.width = c(.90, .5), fill = &quot;skyblue&quot;) + xlim(0, 0.18) + ylab(&quot;theta&quot;) + xlab(&quot;density&quot;) Figure 3.2: 各パターンに対するthetaの事後分布 平均を見るとA案が最もCTRが低く，D案が最もCTRが広いがDは表示回数が少ないため事後分布の裾が広くなっている． これよりB案とD案に絞り，これらの案が他より優れているかどうかを評価してみる． ms &lt;- rstan::extract(fit_simple_model) %&gt;% purrr::pluck(&quot;theta&quot;) tibble( Pattern = c(&quot;A&quot;, &quot;C&quot;), &quot;B&quot; = c(mean(ms[,2] - ms[,1] &gt; 0), mean(ms[,2] - ms[,3] &gt; 0)) %&gt;% round(3), &quot;D&quot; = c(mean(ms[,4] - ms[,1] &gt; 0), mean(ms[,4] - ms[,3] &gt; 0)) %&gt;% round(3) ) %&gt;% knitr::kable( caption = &quot;B,D案とA,C案の比較&quot;, label = &quot;comparing-simple-model-bd-to-ac&quot; ) Table 3.3: B,D案とA,C案の比較 Pattern B D A 0.979 0.942 C 0.931 0.879 B案がA案よりも優れている割合は95%を超えているものの，D案とA案の比較では95%を若干下回っている． "],["id_03-02-00-modelling-1.html", "3.2 モデリング1", " 3.2 モデリング1 要素案の効果を考慮するために以下のようなEquation (3.2) で定義されるモデルがより適切として議論を進める． \\[\\begin{align} \\begin{aligned} \\alpha &amp;\\sim N(\\mu_0, \\sigma_0) \\\\ \\beta_{\\text{banner}} &amp;\\sim N(\\mu_1, \\sigma_1) \\\\ \\beta_{\\text{button}} &amp;\\sim N(\\mu_2, \\sigma_2) \\\\ \\theta &amp;= \\text{logistic}(\\alpha + \\beta_1 + \\beta_2) \\\\ \\text{Click} &amp;\\sim \\text{Binomial}(\\text{Impression}, \\theta) \\end{aligned} \\tag{3.2} \\end{align}\\] ここではデザインで変更を加えた要素に関する情報をダミー変数として持たせ，その効果をモデルに加えている． 対応してダミー変数をデータに加えておく． test_results_2 &lt;- test_results %&gt;% mutate(ctr = round(ctr, 4)) %&gt;% mutate( img = c(0, 0, 1, 1), btn = c(0, 1, 0, 1) ) %&gt;% select(pattern, img, btn, everything()) test_results_2 %&gt;% knitr::kable( caption = &quot;LPのデザイン表示テスト結果&quot;, label = &quot;sample-data-chapter-03&quot; ) %&gt;% kableExtra::kable_styling(full_width = FALSE) Table 3.1: LPのデザイン表示テスト結果 pattern img btn imp click ctr A 0 0 434 8 0.0184 B 0 1 382 17 0.0445 C 1 0 394 10 0.0254 D 1 1 88 4 0.0455 "],["id_03-03-00-ダミー変数.html", "3.3 ダミー変数", " 3.3 ダミー変数 "],["id_03-04-00-logistic-function.html", "3.4 ロジスティック関数", " 3.4 ロジスティック関数 "],["id_03-05-00-normal-distoribution.html", "3.5 正規分布", " 3.5 正規分布 "],["id_03-06-00-modelling-2.html", "3.6 モデリング2", " 3.6 モデリング2 "],["id_03-07-00-wrong-model.html", "3.7 間違ったモデル", " 3.7 間違ったモデル "],["id_03-08-00-interaction.html", "3.8 交互作用", " 3.8 交互作用 "],["id_03-09-00-summary.html", "3.9 まとめ", " 3.9 まとめ "],["id_99_references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
